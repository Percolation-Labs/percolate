{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7f7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 22:00:41.930\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1m[[None]]] got repo for user None with roles [] and repo.role_level=None\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:41.934\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function help\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_executive_info with access level 1\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.226\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_general_info\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.229\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_model_description\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.233\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_partner_info with access level 10\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.237\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_recent_uploads_by_user\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.243\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function save_user_memory\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.246\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search_user_facts\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.249\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_entities\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.252\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.254\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function activate_functions_by_name\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:42.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1m******Constructed agent p8.UserRoleAgent******\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:44.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-5-sonnet-20241022, is_streaming=True\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me look up the details for KT-2011."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 22:00:47.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1m(p8.UserRoleAgent)function_call=FunctionCall(name='get_entities', arguments={'keys': 'KT-2011'}, id='toolu_01W8K8gGFynf5WvY3mvuxJkZ', scheme='anthropic')\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:47.873\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_entities\u001b[0m:\u001b[36m183\u001b[0m - \u001b[34m\u001b[1mget_entities/keys='KT-2011', allow_fuzzy_match=False\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:48.951\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1m[[10e0a97d-a064-553a-9043-3c1f0a6e6725]]] got repo for user 10e0a97d-a064-553a-9043-3c1f0a6e6725 with roles [] and repo.role_level=100\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:49.477\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-5-sonnet-20241022, is_streaming=True\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the entity search results, KT-2011 is the Issa Jumpsuit, a garment body developed for THE KIT brand. Here are the key details:\n",
      "\n",
      "- **Name:** Issa Jumpsuit\n",
      "- **Brand:** THE KIT (KT)\n",
      "- **Category:** Jumpsuit\n",
      "- **Status:** Done (fully onboarded and ready for production)\n",
      "- **Available Sizes:** XS through 3X in both regular and petite sizes\n",
      "- **Body Version:** 10\n",
      "\n",
      "The jumpsuit has been fully digitally onboarded and is ready for production. It has 32 pattern pieces including panels for the bodice and pants sections, pockets, waistband, and other construction elements.\n",
      "\n",
      "The body was originally created in December 2018 and has gone through several versions, with the latest update being version 10. It was developed to work with several onboarding materials including \"LTCSL\", \"CTW70\", and \"CTNOX\".\n",
      "\n",
      "Would you like to know more specific details about this body, such as its measurements, construction specifications, or see what styles have been created using this body?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 22:00:58.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.llm.utils.stream_utils\u001b[0m:\u001b[36m_audit_response\u001b[0m:\u001b[36m352\u001b[0m - \u001b[1mAuditing stream response, content length: 1017\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:58.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.utils.stream_utils\u001b[0m:\u001b[36m_audit_response\u001b[0m:\u001b[36m359\u001b[0m - \u001b[34m\u001b[1mGenerated new session_id for audit: e7de5055-f674-45a0-aaca-6e41411b1f38\u001b[0m\n",
      "\u001b[32m2025-08-10 22:00:59.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.llm.proxy.utils\u001b[0m:\u001b[36maudit_response_for_user\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mAudited session: e7de5055-f674-45a0-aaca-6e41411b1f38 for metadata {'userid': '10e0a97d-a064-553a-9043-3c1f0a6e6725', 'channel_id': None, 'thread_id': 'e7de5055-f674-45a0-aaca-6e41411b1f38', 'query': 'What is KT-2011'}\u001b[0m\n",
      "\u001b[32m2025-08-10 22:01:00.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.llm.proxy.utils\u001b[0m:\u001b[36maudit_response_for_user\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mUpdated user model for: 10e0a97d-a064-553a-9043-3c1f0a6e6725\u001b[0m\n",
      "\u001b[32m2025-08-10 22:01:01.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.proxy.utils\u001b[0m:\u001b[36maudit_response_for_user\u001b[0m:\u001b[36m345\u001b[0m - \u001b[34m\u001b[1mAdded 3 AI Response records\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pytest\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "# Set environment variables BEFORE importing percolate\n",
    "os.environ[\"P8_PG_HOST\"] = \"localhost\"\n",
    "os.environ[\"P8_PG_PORT\"] = \"25432\"\n",
    "os.environ[\"P8_PG_USER\"] = \"postgres\"\n",
    "os.environ[\"P8_PG_PASSWORD\"] = os.environ.get(\"P8_TEST_BEARER_TOKEN\", \"\")\n",
    "os.environ[\"P8_PG_DATABASE\"] = \"app\"\n",
    "import percolate as p8\n",
    "from IPython.display import Markdown\n",
    "from percolate.services import PostgresService\n",
    "\n",
    "from percolate.api.mcp_server.api_repository import APIProxyRepository\n",
    "from percolate.services.llm import CallingContext\n",
    "from percolate.models import UserMemory\n",
    "from percolate.utils.env import MASTER_PROMPT\n",
    "from percolate.services.llm.utils.stream_utils import print_openai_delta_content\n",
    "#p8.repository(UserMemory).register()\n",
    "a = APIProxyRepository( user_email='amartey@gmail.com')\n",
    "pg = PostgresService()\n",
    "from percolate.models.p8 import UserRoleAgent\n",
    "#pg.execute('select id, name, email, role_level from  p8.\"User\" where role_level > 5')\n",
    "#a = APIProxyRepository( api_endpoint='http://localhost:5008', user_email='amartey@gmail.com')\n",
    "#await a.add_memory(\"I want to remember\")\n",
    "#await a.get_memory('unknown_20250728_112052_032')\n",
    "#Markdown(UserRoleAgent.get_model_description())\n",
    "#Markdown(MASTER_PROMPT())\n",
    "#agent = p8.Agent(UserRoleAgent)\n",
    "#context = CallingContext(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', role_level=10)\n",
    "# r = agent.stream(\"what is 2 + 2\",context=context, limit=2)\n",
    "# for item in r.iter_lines():\n",
    "#     #print(item)\n",
    "#     print_openai_delta_content(item.decode())\n",
    "\n",
    "agent = p8.Agent(UserRoleAgent)\n",
    " \n",
    "context = CallingContext(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', role_level=10,\n",
    "                         model='claude-3-5-sonnet-20241022',\n",
    "                         limit = 7\n",
    "                        )\n",
    "\n",
    "# for s in agent.stream(\"What can you tell me about create one\", context=context).iter_lines():\n",
    "#     print_openai_delta_content(s)\n",
    "\n",
    "#Markdown(agent(\"what is KT-2011\"))\n",
    "\n",
    "for s in agent.stream(\"What is KT-2011\", context=context).iter_lines():\n",
    "    #print(s)\n",
    "    print_openai_delta_content(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fffcbf0-96fa-4ac4-9a18-80d0fb0e0244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'null'},\n",
       " {'role': 'user',\n",
       "  'content': '{\"Info\": \"You can use the users context - observe the current chat thread which may be empty when deciding if the user is referring to something they discussed recently or a new context.When you do use this context do not explain that to the user as it would be jarring for them. Freely use this context if its relevant or necessary to understand the user context.The last AI Response from the previous interaction is added for extra context and can be used if the user asks a follow up question in reference to previous response only. But dont ask them for confirmation.If entity keys are provided you can use the get-entities lookup function to load and inspect them.some tools may accept a user id and you can use the user id here for those tool calls e.g. to do user specific searches\", \"recent_threads\": [{\"questions\": [\"What is KT-2011\"], \"thread_id\": \"a7548d9e-0537-4bba-b787-efe5a27c199a\", \"thread_timestamp\": \"2025-08-10T20:56:00.114385\"}], \"last_ai_response\": \"I could not find an exact match for \\\\\"KT-2011\\\\\" in the system. However, the closest match is KT-92011, which appears to be an order for THE KIT brand. Here\\\\u2019s what I found about KT-92011:\\\\n\\\\n- **Order Number:** KT-92011\\\\n- **Brand:** THE KIT (KT)\\\\n- **Status:** Pending Inventory\\\\n- **Order Channel:** Shopify (ECOM)\\\\n- **Line Items (Styles):**\\\\n  - KT-3093 LY115 BBFCPZ 4ZZLG\\\\n  - KT-3030 CTW70 NAVYHN 4ZZLG\\\\n- **Active Production Requests (ONEs):** 10449136, 10449137\\\\n- **Order Link:** [Airtable Record](https://airtable.com/appfaTObyfrmPHvHc/tblhtedTR2AFCpd8A/recVtUXuOLU0eA84c)\\\\n\\\\nIt\\\\u2019s possible that \\\\\"KT-2011\\\\\" is a typo or a misremembered code. If you meant something else, or want details about a different entity (like a body, style, or material), please clarify or provide more context.\\\\n\\\\nWould you like more details about the order KT-92011 or its line items?\", \"interesting_entity_keys\": {}, \"users_name\": \"Saoirse Amarteifio\", \"about user\": \"This user demonstrates frequent engagement with file management and data retrieval features, including queries about recent uploads, file contents, and entity-based data exploration. Their activity indicates an interest in understanding system functionalities such as \\\\\"create-one\\\\\" and document chunking, suggesting a focus on content organization and knowledge management. Usage patterns also reflect regular interaction with basic system commands and access level inquiries.\", \"user_id\": \"10e0a97d-a064-553a-9043-3c1f0a6e6725\"}'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [{'id': 'call_7Py89PbXdD7xNRCTAZlKhjr2',\n",
       "    'type': 'function',\n",
       "    'function': {'name': 'get_entities',\n",
       "     'arguments': '{\"keys\": \"KT-2011\"}'}}]},\n",
       " {'role': 'tool',\n",
       "  'content': '{\"get_entities\": {\"design.bodies\": {\"data\": null, \"metadata\": null, \"instruction\": \"you can request to activate new functions by name to use them as tools\"}}}',\n",
       "  'tool_call_id': 'call_7Py89PbXdD7xNRCTAZlKhjr2'},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [{'id': 'call_dV0CA5MLaLSCkDjGGU7Als4c',\n",
       "    'type': 'function',\n",
       "    'function': {'name': 'get_entities',\n",
       "     'arguments': '{\"keys\": \"KT2011\", \"allow_fuzzy_match\": true}'}}]},\n",
       " {'role': 'tool',\n",
       "  'content': '{\"get_fuzzy_entities\": {\"entities\": {\"meta.brands\": {\"data\": null, \"metadata\": null, \"instruction\": \"you can request to activate new functions by name to use them as tools\"}, \"sell.orders\": {\"data\": [{\"id\": \"2f25b356-83b9-3a3d-cd43-7cc8acf5c303\", \"name\": \"KT-92011\", \"status\": \"Order is PENDING INVENTORY\", \"userid\": null, \"groupid\": null, \"is_open\": true, \"record_id\": \"recVtUXuOLU0eA84c\", \"brand_code\": \"KT\", \"brand_name\": \"THE KIT\", \"created_at\": \"2025-07-18T22:32:28\", \"deleted_at\": \"2025-07-18T22:40:55.275523\", \"updated_at\": \"2025-08-02T23:40:40.442781\", \"is_canceled\": false, \"is_fulfilled\": false, \"order_number\": \"KT-92011\", \"order_channel\": \"Shopify\", \"sales_channel\": \"ECOM\", \"line_item_skus\": [\"KT-3093 LY115 BBFCPZ 4ZZLG\", \"KT-3030 CTW70 NAVYHN 4ZZLG\"], \"shipping_label\": \"https://ss6.shipstation.com/#/orders\", \"last_updated_at\": \"2025-08-01T00:03:37\", \"financial_status\": \"paid\", \"order_created_at\": \"2025-07-18T22:32:28\", \"predicted_done_at\": null, \"active_one_numbers\": [\"10449136\", \"10449137\"], \"warehouse_location\": null, \"airtable_record_link\": \"https://airtable.com/appfaTObyfrmPHvHc/tblhtedTR2AFCpd8A/recVtUXuOLU0eA84c\", \"flag_for_review_nodes\": null, \"shipping_tracking_numbers\": \"\", \"line_items_without_production_requests\": 0}], \"metadata\": null, \"instruction\": \"you can request to activate new functions by name to use them as tools\"}, \"design.bodies\": {\"data\": null, \"metadata\": null, \"instruction\": \"you can request to activate new functions by name to use them as tools\"}}, \"search_metadata\": {\"matched_keys\": [\"KT-2011\", \"KT-92011\", \"KT2\"], \"search_terms\": [\"KT2011\"], \"matched_keys_count\": 3, \"max_matches_per_term\": 5, \"similarity_threshold\": 0.3}}}',\n",
       "  'tool_call_id': 'call_dV0CA5MLaLSCkDjGGU7Als4c'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7765b95a-4414-4059-b676-b98a69b3ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-C36PCju0Q53UtYAq0wP59N9Vn6zFr', 'object': 'chat.completion.chunk', 'created': 1754855642, 'model': 'gpt-4.1-2025-04-14', 'service_tier': 'default', 'system_fingerprint': 'fp_51e1070cf2', 'choices': [{'index': 0, 'delta': {}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': None, 'obfuscation': '1igNZ7gl6'}\n"
     ]
    }
   ],
   "source": [
    "def _parse_open_ai_response(json_data):\n",
    "    \"\"\"Parse OpenAI response data\"\"\"\n",
    "    content = \"\"\n",
    "    if \"choices\" in json_data and len(json_data[\"choices\"]) > 0:\n",
    "        choice = json_data[\"choices\"][0]\n",
    "        if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n",
    "            content = choice[\"delta\"][\"content\"]\n",
    "    return content\n",
    "def print_openai_delta_content(json_data):\n",
    "    \"\"\"Print content from OpenAI delta response\"\"\"\n",
    "    try:\n",
    "        try:\n",
    "            json_data = json_data.decode()\n",
    "        except:\n",
    "            pass\n",
    "        p = json_data.index(\":\")\n",
    "        json_data = json_data[p + 1 :]\n",
    "        data = json.loads(json_data)\n",
    "        print(data)\n",
    "        content = _parse_open_ai_response(data)\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "            return content\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "print_openai_delta_content(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb8f5ca-3214-496b-b8b6-a05ef4963a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = b'data: {\"id\": \"chatcmpl-C36PCju0Q53UtYAq0wP59N9Vn6zFr\", \"object\": \"chat.completion.chunk\", \"created\": 1754855642, \"model\": \"gpt-4.1-2025-04-14\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_51e1070cf2\", \"choices\": [{\"index\": 0, \"delta\": {}, \"logprobs\": null, \"finish_reason\": \"stop\"}], \"usage\": null, \"obfuscation\": \"1igNZ7gl6\"}\\n\\n'\n",
    "print_openai_delta_content(x.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cac04cf-fe60-4c6a-94be-85d08e086176",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = CallingContext(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', role_level=10, model='claude-3-7-sonnet-20250219')\n",
    "# r = agent.stream(\"what is 2 + 2\",context=context, limit=2)\n",
    "# for item in r.iter_lines():\n",
    "#     print_openai_delta_content(item.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00b5e763-c73b-49bf-a2be-ba5af76c8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 17:12:53.177\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m322\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-7-sonnet-20250219, is_streaming=True\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from percolate.services.llm import (\n",
    "    CallingContext,\n",
    "    FunctionCall,\n",
    "    LanguageModel,\n",
    "    MessageStackFormatter,\n",
    ")\n",
    "from percolate.services.llm.utils import (\n",
    "    sse_openai_compatible_stream_with_tool_call_collapse\n",
    ")\n",
    "\n",
    "from percolate.services.llm.proxy.stream_generators import stream_with_buffered_functions\n",
    "\n",
    "M = UserRoleAgent.build_message_stack(\"What is the captial of ireland\")\n",
    "context = CallingContext.with_model('claude-3-7-sonnet-20250219').in_streaming_mode()\n",
    "lm_client = LanguageModel.from_context(context)\n",
    "raw_response = lm_client._call_raw(\n",
    "        messages=M,\n",
    "        functions=None,\n",
    "        context=context,\n",
    "    )\n",
    "raw_response\n",
    "\n",
    "#internally uses response.iter_lines\n",
    "\n",
    "# for line, chunk in sse_openai_compatible_stream_with_tool_call_collapse(\n",
    "#                 raw_response\n",
    "#             ):\n",
    "#         print(line, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e80ab13-8815-458d-b063-027210b48e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 17:55:54.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1m[[None]]] got repo for user None with roles [] and repo.role_level=None\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:54.908\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function help\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.200\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_executive_info with access level 1\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.204\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_general_info\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_model_description\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.209\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_partner_info with access level 10\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_recent_uploads_by_user\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.215\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function save_user_fact\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.218\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search_user_facts\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_entities\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.223\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function activate_functions_by_name\u001b[0m\n",
      "\u001b[32m2025-08-10 17:55:55.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m******Constructed agent p8.UserRoleAgent******\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = p8.Agent(UserRoleAgent)\n",
    "#agent.get_entities('KT-2011') #Box File: Cap Table 11.15.2023.xlsx\n",
    "#agent.get_entities('qa_circuits_memory.md') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ed56f0-df0c-4b4c-946c-b3349658ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'get_entities': {'p8.Resources': {'data': [{'id': 'f52aafda-a8b8-5785-b46a-0e7f5a8e69fb',\n",
       "     'uri': 's3://res-data-platform/users/10e0a97d-a064-553a-9043-3c1f0a6e6725/Memory note about considering circuits for Q&A systems/qa_circuits_memory.md',\n",
       "     'name': 'qa_circuits_memory.md',\n",
       "     'userid': '10e0a97d-a064-553a-9043-3c1f0a6e6725',\n",
       "     'content': '# Memory: Consider Circuits for Q&A\\n\\n**Date:** July 27, 2025\\n**Priority:** Important\\n\\n## Note\\nNeed to consider the circuits for Q&A implementation.\\n\\n## Context\\n- This is a reminder to evaluate circuit design patterns for question and answer systems\\n- May relate to system architecture, data flow, or processing pathways\\n- Important consideration for future development or current project analysis\\n\\n## Action Items\\n- Review circuit requirements for Q&A functionality\\n- Analyze current circuit implementations\\n- Consider optimization opportunities\\n\\n---\\n*This memory was saved via Percolate MCP interface*',\n",
       "     'groupid': None,\n",
       "     'ordinal': 0,\n",
       "     'summary': None,\n",
       "     'user_id': None,\n",
       "     'category': 'text_chunk',\n",
       "     'metadata': {'file_type': 'text',\n",
       "      'chunk_size': 1000,\n",
       "      'chunk_index': 0,\n",
       "      'source_file': 'qa_circuits_memory.md',\n",
       "      'original_uri': 's3://res-data-platform/users/10e0a97d-a064-553a-9043-3c1f0a6e6725/Memory note about considering circuits for Q&A systems/qa_circuits_memory.md',\n",
       "      'parsing_mode': 'simple',\n",
       "      'total_chunks': 1,\n",
       "      'chunk_overlap': 200},\n",
       "     'created_at': '2025-07-27T22:05:39.22094',\n",
       "     'deleted_at': None,\n",
       "     'updated_at': '2025-08-09T18:40:24.611146',\n",
       "     'graph_paths': None,\n",
       "     'resource_timestamp': '2025-07-27T22:05:39.211257',\n",
       "     'required_access_level': 5}],\n",
       "   'metadata': None,\n",
       "   'instruction': 'you can request to activate new functions by name to use them as tools'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pg.execute(\"\"\" select * from p8.\"User\" where email ='amartey@gmail.com' \"\"\")\n",
    "#UserRoleAgent.get_recent_uploads_by_user('10e0a97d-a064-553a-9043-3c1f0a6e6725')\n",
    "\n",
    "from percolate.services import PostgresService\n",
    "\n",
    "#does not work\n",
    "pg = PostgresService(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725')\n",
    "pg.get_entities('qa_circuits_memory.md')\n",
    "#works\n",
    "# pg = PostgresService()\n",
    "# pg.get_entities('qa_circuits_memory.md')\n",
    "# #works\n",
    "# pg = PostgresService(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725')\n",
    "# pg.get_entities('KT-2011')\n",
    "# #works\n",
    "# pg = PostgresService()\n",
    "# pg.get_entities('KT-2011')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec5ab15-c2b6-4b28-a5dc-25af58afeece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the information gathered, I can provide a comprehensive overview of Create ONE:\\n\\n# Create ONE Platform Overview\\n\\nCreate ONE is Resonance's integrated platform that serves as the central interface for fashion brands to manage their entire garment production lifecycle. Here's a detailed breakdown:\\n\\n```mermaid\\nflowchart TD\\n    A[Create ONE Platform] --> B[Design]\\n    A --> C[Sell]\\n    A --> D[Manufacture]\\n    \\n    B --> B1[Digital Garment Design]\\n    B --> B2[Core Body Templates]\\n    B --> B3[Product Onboarding]\\n    \\n    C --> C1[Order Management]\\n    C --> C2[Multiple Sales Channels]\\n    \\n    D --> D1[Production Requests]\\n    D --> D2[Manufacturing Lifecycle]\\n    D --> D3[Digital Factory Integration]\\n```\\n\\n## Key Features and Capabilities\\n\\n1. **Design Capabilities**\\n   - Complete digital garment design interface\\n   - Access to pre-validated core body templates\\n   - Ability to modify existing designs or create new ones\\n   - Product onboarding tools\\n\\n2. **Sales Integration**\\n   - Multiple sales channel support (Wholesale, Shopify, etc.)\\n   - Order management system\\n   - Unique coding system for tracking (e.g., BR-0000 format)\\n\\n3. **Manufacturing Management**\\n   - Production request handling (ONEs)\\n   - End-to-end production lifecycle management\\n   - Integration with digital factories\\n   - On-demand production capabilities\\n\\n## Platform Benefits\\n\\n- **Streamlined Workflow**: Integrated design-to-delivery process\\n- **Flexibility**: Brands can use existing templates or create custom designs\\n- **Efficiency**: Digital-first approach to fashion production\\n- **Scalability**: Supports multiple sales channels and production methods\\n- **Traceability**: Comprehensive tracking through unique coding systems\\n\\nThe platform is designed to revolutionize fashion manufacturing by providing brands with a complete digital ecosystem for their operations, from initial design concepts through to final production and delivery.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efa720b-0183-406e-8ef9-4d21430df17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-10 18:15:47.374\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m91\u001b[0m - \u001b[34m\u001b[1m[[None]]] got repo for user None with roles [] and repo.role_level=None\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.380\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function help\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.670\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_executive_info with access level 1\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.675\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_general_info\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.677\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_model_description\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.680\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m64\u001b[0m - \u001b[34m\u001b[1madded function get_partner_info with access level 10\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.684\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_recent_uploads_by_user\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.688\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function save_user_fact\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.690\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search_user_facts\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.693\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function get_entities\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.696\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function search\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m66\u001b[0m - \u001b[34m\u001b[1madded function activate_functions_by_name\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:47.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m******Constructed agent p8.UserRoleAgent******\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:49.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.utils.env\u001b[0m:\u001b[36m_load_prompt\u001b[0m:\u001b[36m260\u001b[0m - \u001b[1mLoaded master prompt from database\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:49.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:50.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m293\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id=None, channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], role_level=None, streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:52.771\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-5-sonnet-20241022, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:54.835\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m293\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='claude-3-5-sonnet-20241022', file_uris=[], role_level=10, streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:54.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1m(p8.UserRoleAgent)function_call=FunctionCall(name='get_general_info', arguments={'question': 'What is Create ONE platform and its main features and purpose?'}, id='toolu_01FXQ67sC9668rTMKtE59itd', scheme='anthropic')\u001b[0m\n",
      "\u001b[32m2025-08-10 18:15:57.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-5-sonnet-20241022, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-08-10 18:16:00.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m293\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='claude-3-5-sonnet-20241022', file_uris=[], role_level=10, streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-08-10 18:16:00.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1m(p8.UserRoleAgent)function_call=FunctionCall(name='get_general_info', arguments={'question': 'What are the main features and capabilities of Create ONE platform for brands?'}, id='toolu_01ExS2QAQzA1BfVdpfpZXEvF', scheme='anthropic')\u001b[0m\n",
      "\u001b[32m2025-08-10 18:16:02.045\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m432\u001b[0m - \u001b[34m\u001b[1minvoking model claude-3-5-sonnet-20241022, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-08-10 18:16:11.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m293\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='claude-3-5-sonnet-20241022', file_uris=[], role_level=10, streaming_callback=None, response_callback=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the information gathered, I can provide a comprehensive overview of Create ONE:\n",
       "\n",
       "# Create ONE Platform Overview\n",
       "\n",
       "Create ONE is Resonance's integrated platform that serves as the central interface for fashion brands to manage their entire garment production lifecycle. Here's a detailed breakdown:\n",
       "\n",
       "```mermaid\n",
       "flowchart TD\n",
       "    A[Create ONE Platform] --> B[Design]\n",
       "    A --> C[Sell]\n",
       "    A --> D[Manufacture]\n",
       "    \n",
       "    B --> B1[Digital Garment Design]\n",
       "    B --> B2[Core Body Templates]\n",
       "    B --> B3[Product Onboarding]\n",
       "    \n",
       "    C --> C1[Order Management]\n",
       "    C --> C2[Multiple Sales Channels]\n",
       "    \n",
       "    D --> D1[Production Requests]\n",
       "    D --> D2[Manufacturing Lifecycle]\n",
       "    D --> D3[Digital Factory Integration]\n",
       "```\n",
       "\n",
       "## Key Features and Capabilities\n",
       "\n",
       "1. **Design Capabilities**\n",
       "   - Complete digital garment design interface\n",
       "   - Access to pre-validated core body templates\n",
       "   - Ability to modify existing designs or create new ones\n",
       "   - Product onboarding tools\n",
       "\n",
       "2. **Sales Integration**\n",
       "   - Multiple sales channel support (Wholesale, Shopify, etc.)\n",
       "   - Order management system\n",
       "   - Unique coding system for tracking (e.g., BR-0000 format)\n",
       "\n",
       "3. **Manufacturing Management**\n",
       "   - Production request handling (ONEs)\n",
       "   - End-to-end production lifecycle management\n",
       "   - Integration with digital factories\n",
       "   - On-demand production capabilities\n",
       "\n",
       "## Platform Benefits\n",
       "\n",
       "- **Streamlined Workflow**: Integrated design-to-delivery process\n",
       "- **Flexibility**: Brands can use existing templates or create custom designs\n",
       "- **Efficiency**: Digital-first approach to fashion production\n",
       "- **Scalability**: Supports multiple sales channels and production methods\n",
       "- **Traceability**: Comprehensive tracking through unique coding systems\n",
       "\n",
       "The platform is designed to revolutionize fashion manufacturing by providing brands with a complete digital ecosystem for their operations, from initial design concepts through to final production and delivery."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = p8.Agent(UserRoleAgent)\n",
    "r = agent(\"what is 2 + 2\")\n",
    "Markdown(r)\n",
    "context = CallingContext(user_id='10e0a97d-a064-553a-9043-3c1f0a6e6725', role_level=10,\n",
    "                         #model='claude-3-7-sonnet-20250219'\n",
    "                         model = 'claude-3-5-sonnet-20241022'\n",
    "                        )\n",
    "#r=agent('what functions do you have available - including the ones loaded as tools?', context=None)\n",
    "#r=agent('please search the executive resources for information about resonance patents', context=context)\n",
    "#r=agent('Can you tell me about KT-2011', context=context)\n",
    "#once db user is app this is restricted\n",
    "#r=agent('Can you tell me about KT-2011', context=CallingContext(role_level=10, user_id='3120a781-9c13-5dbd-8c18-9e72dc63f272'))\n",
    "\n",
    "#shoud return useful info about create one from synced files\n",
    "#r = agent(\"please give  me information about create one explaining what create one allows brands to do \")\n",
    "\n",
    "r = agent(\"What can you tell me about create one\", context=context)\n",
    "\n",
    "\n",
    "\n",
    "Markdown(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81cbdd-6d8b-4e8e-ba8d-8d7043f4f993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c924fb1-7bb6-4d27-8424-2afc6894e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = p8.try_load_model(\"public.CreateOneResources\", allow_abstract=True)\n",
    "repo = p8.repository(model)\n",
    "repo.search(\"What is Create ONE and what does it allow brands to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6eef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = p8.try_load_model('design.bodies')\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.services import PostgresService\n",
    "from percolate.utils import make_uuid\n",
    "with open ('/Users/sirsh/code/mr_saoirse/percolate/.res/master_prompt.md') as f:\n",
    "    p = f.read()\n",
    "    settings_id = str(make_uuid({\"key\": \"system_prompt\"}))\n",
    "\n",
    "    query = '''\n",
    "    INSERT INTO p8.\"Settings\" (id, key, value, created_at, updated_at)\n",
    "    VALUES (%s, %s, %s, NOW(), NOW())\n",
    "    ON CONFLICT (id) DO UPDATE \n",
    "    SET value = EXCLUDED.value, updated_at = NOW()\n",
    "    '''\n",
    "    pg.execute(query, (settings_id, 'system_prompt', p))\n",
    "\n",
    "Markdown(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = p8.try_load_model('executive.ExecutiveResources')\n",
    "#p8.repository(loaded).search(\"Tell me about resonance companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc248e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54daa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = p8.Agent(loaded).stream(\"tell me about resonance companies\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in r.iter_lines():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfea910-cd35-4ec4-b161-cba90a2553a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.services import PostgresService\n",
    "\n",
    "#pg = PostgresService(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')\n",
    "pg = PostgresService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fe271-c015-4241-a79d-372d8b7a206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.execute(\"\"\" select * from executive.\"ExecutiveResources\" limit 1 \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4adbed-56c0-4b6b-9937-810ded7719d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g = await a.stream_chat(\"tell me about the company\", stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#await a.get_entity('kt2011')\n",
    "r = await a.search_entities(\"Looking for entities learning about bodies\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1df098",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await a.search_entities(\"Im looking for summer dresses\",entity_name='design.bodies')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9196f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r[0].keys())\n",
    "r[0]['vector_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = await a.stream_chat(\"tell me about the resonance company\", stream=False)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6795ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = await a.stream_chat(\"tell me about the resonance company\", stream=False, agent='executive-ExecutiveResources')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5044a-b339-4dee-a90e-0e02a4eab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.execute(\"select body_code from design.bodies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee38590-334e-45cf-845f-539e4c9ec6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.get_entities('KT-2011'), pg.get_entities('ZF-3005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf41aa8-e390-4275-b0a5-0972bcb9849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.services.llm import CallingContext\n",
    "import percolate as p8\n",
    "from percolate.models import Resources\n",
    "\n",
    "ctx = CallingContext(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')\n",
    "a = p8.Agent(Resources,allow_help=False)\n",
    "#a.get_entities('ZF-3005')\n",
    "a(\"get me KT-2011\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37103b41-5193-4b69-89ae-29230fa3b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a(\"get me ZF-3005\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6ccb8-4c94-4ee3-8db9-fb5aa54bfd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085421d-7e23-4f04-bb2e-743917070c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
