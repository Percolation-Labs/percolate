{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7f7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytest\n",
    "# Set environment variables BEFORE importing percolate\n",
    "os.environ[\"P8_PG_HOST\"] = \"localhost\"\n",
    "os.environ[\"P8_PG_PORT\"] = \"25432\"\n",
    "os.environ[\"P8_PG_USER\"] = \"app\"\n",
    "os.environ[\"P8_PG_PASSWORD\"] = os.environ.get(\"P8_TEST_BEARER_TOKEN\", \"\")\n",
    "os.environ[\"P8_PG_DATABASE\"] = \"app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfea910-cd35-4ec4-b161-cba90a2553a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-docx not installed, DOCX support limited\n",
      "pypdf not available, PDF text extraction will be limited\n"
     ]
    }
   ],
   "source": [
    "from percolate.services import PostgresService\n",
    "\n",
    "pg = PostgresService(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478fe271-c015-4241-a79d-372d8b7a206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRAND:KT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.user_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a5044a-b339-4dee-a90e-0e02a4eab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.execute(\"select body_code from design.bodies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee38590-334e-45cf-845f-539e4c9ec6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.get_entities('KT-2011'), pg.get_entities('ZF-3005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf41aa8-e390-4275-b0a5-0972bcb9849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-13 06:32:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[None]]] got repo for user None with roles [] and None\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function chunked_resource\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function chunked_resource_from_text\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.825\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function get_recent_uploads_by_user\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function save_user_fact\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function search_facts_by_users\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.830\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function get_entities\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.831\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function search\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.832\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function activate_functions_by_name\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:07.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m******Constructed agent p8.Resources******\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:08.800\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:09.694\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:09.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='get_entities', arguments={'keys': 'KT-2011'}, id='call_ifTX9gEjnXOfxp3y5fExr7KX', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:09.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_entities\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mget_entities/keys='KT-2011', allow_fuzzy_match=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:10.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[3a9fb64e-8f26-511f-9ff3-09f0088d3b17]]] got repo for user 3a9fb64e-8f26-511f-9ff3-09f0088d3b17 with roles ['BRAND:KT'] and 10\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:11.826\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:19.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are the details for KT-2011:\\n\\n- **Name:** KT-2011 (Issa Jumpsuit)\\n- **Category:** Jumpsuit\\n- **Status:** Done\\n- **Brand Code:** KT\\n- **Body Version:** 10\\n- **Available Sizes:** XS, S, M, L, XL, 2X, 3X, P-XS, P-S, P-M, P-L, P-XL, P-2X, P-3X\\n- **Body Pieces:** 32 unique pieces (e.g., BODFTPNLRT-S, PNTFTPNLLF-S, etc.)\\n- **Onboarding Material Codes:** LTCSL, CTW70, CTNOX\\n- **Airtable Record:** [View in Airtable](https://airtable.com/appa7Sw0ML47cA8D1/tblXXuR9kBZvbRqoU/recKwuCplMnkWJvq5)\\n\\n**Images:**\\n- Cover Image:  \\n  ![Cover](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/cover_images/recKwuCplMnkWJvq5/screen-shot-2018-03-02-at-4_34_17-pm.png)\\n- Body Images:  \\n  ![Body Back](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/body_images/recKwuCplMnkWJvq5/kt-2011-v9-3d-body-back-colorway-1.png)  \\n  ![Body Front](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/body_images/recKwuCplMnkWJvq5/kt-2011-v9-3d-body-colorway-1.png)\\n\\nIf you need more details (such as a breakdown of body pieces or onboarding materials), let me know!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from percolate.services.llm import CallingContext\n",
    "import percolate as p8\n",
    "from percolate.models import Resources\n",
    "\n",
    "ctx = CallingContext(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')\n",
    "a = p8.Agent(Resources,allow_help=False)\n",
    "#a.get_entities('ZF-3005')\n",
    "a(\"get me KT-2011\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37103b41-5193-4b69-89ae-29230fa3b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-13 06:32:20.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:21.468\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:21.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='get_entities', arguments={'keys': 'ZF-3005'}, id='call_6TQQ4Y4BLU5835Edy2svkXpz', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:21.471\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_entities\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mget_entities/keys='ZF-3005', allow_fuzzy_match=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:22.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[3a9fb64e-8f26-511f-9ff3-09f0088d3b17]]] got repo for user 3a9fb64e-8f26-511f-9ff3-09f0088d3b17 with roles ['BRAND:KT'] and 10\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:22.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:23.915\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:23.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='activate_functions_by_name', arguments={'function_names': ['design.bodies_get']}, id='call_u5ZWCswlS8w7xKp9JUj9rWfA', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:23.917\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mactivate_functions_by_name\u001b[0m:\u001b[36m147\u001b[0m - \u001b[34m\u001b[1mactivating function ['design.bodies_get'] - ill replace any '.' with underscores!!\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:24.866\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_functions_by_key\u001b[0m:\u001b[36m81\u001b[0m - \u001b[33m\u001b[1mWe could not find the function {'design.bodies_get'}\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:24.868\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:26.431\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I attempted to retrieve information about \"ZF-3005,\" but the relevant function to access this data could not be loaded at the moment. If you have more context about what \"ZF-3005\" refers to (such as a product, part, or document), or if you need information from a specific source, please let me know so I can assist you further or try a different approach.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(\"get me ZF-3005\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6ccb8-4c94-4ee3-8db9-fb5aa54bfd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085421d-7e23-4f04-bb2e-743917070c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
