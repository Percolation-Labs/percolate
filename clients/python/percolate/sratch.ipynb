{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7f7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pytest\n",
    "# Set environment variables BEFORE importing percolate\n",
    "os.environ[\"P8_PG_HOST\"] = \"localhost\"\n",
    "os.environ[\"P8_PG_PORT\"] = \"25432\"\n",
    "os.environ[\"P8_PG_USER\"] = \"app\"\n",
    "os.environ[\"P8_PG_PASSWORD\"] = os.environ.get(\"P8_TEST_BEARER_TOKEN\", \"\")\n",
    "os.environ[\"P8_PG_DATABASE\"] = \"app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfea910-cd35-4ec4-b161-cba90a2553a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-docx not installed, DOCX support limited\n",
      "pypdf not available, PDF text extraction will be limited\n"
     ]
    }
   ],
   "source": [
    "from percolate.services import PostgresService\n",
    "\n",
    "pg = PostgresService(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478fe271-c015-4241-a79d-372d8b7a206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRAND:KT']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.user_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a5044a-b339-4dee-a90e-0e02a4eab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.execute(\"select body_code from design.bodies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee38590-334e-45cf-845f-539e4c9ec6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.get_entities('KT-2011'), pg.get_entities('ZF-3005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf41aa8-e390-4275-b0a5-0972bcb9849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-13 06:32:45.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[None]]] got repo for user None with roles [] and repo.role_level=None\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.049\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function chunked_resource\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function chunked_resource_from_text\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.054\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function get_recent_uploads_by_user\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.057\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function save_user_fact\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function search_facts_by_users\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.063\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function get_entities\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function search\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_function\u001b[0m:\u001b[36m42\u001b[0m - \u001b[34m\u001b[1madded function activate_functions_by_name\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:46.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m******Constructed agent p8.Resources******\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:47.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:47.685\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:47.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='get_entities', arguments={'keys': 'KT-2011'}, id='call_C4yqzMdzK8udZkopVw7Q0JqR', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:47.706\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_entities\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mget_entities/keys='KT-2011', allow_fuzzy_match=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:48.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[3a9fb64e-8f26-511f-9ff3-09f0088d3b17]]] got repo for user 3a9fb64e-8f26-511f-9ff3-09f0088d3b17 with roles ['BRAND:KT'] and repo.role_level=10\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:49.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:54.957\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is the information for KT-2011:\\n\\n---\\n\\n### KT-2011: Issa Jumpsuit\\n\\n- **Category:** Jumpsuit\\n- **Body Code:** KT-2011\\n- **Body Name:** Issa Jumpsuit\\n- **Brand Code:** KT\\n- **Status:** Done\\n- **Available Sizes:** XS, S, M, L, XL, 2X, 3X, P-XS, P-S, P-M, P-L, P-XL, P-2X, P-3X\\n- **Body Version:** 10\\n- **Onboarding Material Codes:** LTCSL, CTW70, CTNOX\\n- **Airtable Record:** [View in Airtable](https://airtable.com/appa7Sw0ML47cA8D1/tblXXuR9kBZvbRqoU/recKwuCplMnkWJvq5)\\n\\n#### Images\\n- ![Back View](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/body_images/recKwuCplMnkWJvq5/kt-2011-v9-3d-body-back-colorway-1.png)\\n- ![Front View](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/body_images/recKwuCplMnkWJvq5/kt-2011-v9-3d-body-colorway-1.png)\\n- ![Cover Image](https://res-data-platform.s3.amazonaws.com/airtable/attachments/tblXXuR9kBZvbRqoU/cover_images/recKwuCplMnkWJvq5/screen-shot-2018-03-02-at-4_34_17-pm.png)\\n\\n#### Body Pieces\\n- BODFTPNLRT-S, BODFTPNLLF-S, BODBKPNL-S, PNTFTPNLLF-S, PNTBKPNLRT-S, BODFTPLKRT-BF, BODFTPLKLF-BF, BODFTPKTLF-S, BODFTPKTRT-S, BODSLPNLRT-S, BODSLPNLLF-S, BODWTDRT-S, BODNKCLSTP-BF, BODNKCLSUN-BF, PNTSDPKBRTTP-S, PNTSDPKBLFTP-S, PNTSDPKBRTUN-S, PNTSDPKBLFUN-S, PNTBKPKTRT-S, PNTBKPKTLF-S, PNTSDPOGRTTP-F, PNTSDPOGRTUN-F, PNTSDPOGLFUN-F, BODFTPLKRT-X, PNTBKPNLLF-S, PNTSDPOGLFTP-F, PNTFTPNL-X, PNTFTPNLRT-S, BODFTPNL-X, PNTBKPNL-X, PNTFWBTHRT-F, PNTFWBTHLF-F\\n\\n---\\n\\nIf you need more details or specific files, let me know!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from percolate.services.llm import CallingContext\n",
    "import percolate as p8\n",
    "from percolate.models import Resources\n",
    "\n",
    "ctx = CallingContext(user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17')\n",
    "a = p8.Agent(Resources,allow_help=False)\n",
    "#a.get_entities('ZF-3005')\n",
    "a(\"get me KT-2011\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37103b41-5193-4b69-89ae-29230fa3b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-13 06:32:55.913\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:56.485\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:56.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='get_entities', arguments={'keys': 'ZF-3005'}, id='call_N68FxiAjFeqqfHiW1LY1AkEj', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:56.487\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_entities\u001b[0m:\u001b[36m182\u001b[0m - \u001b[34m\u001b[1mget_entities/keys='ZF-3005', allow_fuzzy_match=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:57.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mget_repo\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[[3a9fb64e-8f26-511f-9ff3-09f0088d3b17]]] got repo for user 3a9fb64e-8f26-511f-9ff3-09f0088d3b17 with roles ['BRAND:KT'] and repo.role_level=10\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:57.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:58.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:58.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36minvoke\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1m(p8.Resources)function_call=FunctionCall(name='activate_functions_by_name', arguments={'function_names': ['design.bodies_get']}, id='call_25vZW4Z3uG41Q9nLtx3NzZyL', scheme=None)\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:58.649\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.ModelRunner\u001b[0m:\u001b[36mactivate_functions_by_name\u001b[0m:\u001b[36m147\u001b[0m - \u001b[34m\u001b[1mactivating function ['design.bodies_get'] - ill replace any '.' with underscores!!\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:59.677\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpercolate.services.FunctionManager\u001b[0m:\u001b[36madd_functions_by_key\u001b[0m:\u001b[36m81\u001b[0m - \u001b[33m\u001b[1mWe could not find the function {'design.bodies_get'}\u001b[0m\n",
      "\u001b[32m2025-07-13 06:32:59.679\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36mcall_api_simple\u001b[0m:\u001b[36m320\u001b[0m - \u001b[34m\u001b[1minvoking model gpt-4.1, is_streaming=False\u001b[0m\n",
      "\u001b[32m2025-07-13 06:33:01.506\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpercolate.services.llm.LanguageModel\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m198\u001b[0m - \u001b[34m\u001b[1mresponse=<Response [200]>, context=CallingContext(session_id=None, chat_id=None, session_context=None, prefer_json=False, response_model=None, username=None, user_id='3a9fb64e-8f26-511f-9ff3-09f0088d3b17', channel_context=None, channel_ts=None, prefers_streaming=False, is_hybrid_streaming=False, temperature=0.0, plan=None, max_iterations=5, model='gpt-4.1', file_uris=[], streaming_callback=None, response_callback=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I attempted to retrieve information about \"ZF-3005,\" but it appears that the relevant function to access this data is currently unavailable. If you have more context about what \"ZF-3005\" refers to (such as a product, document, or part), or if you can provide additional details, I can try searching for related resources or information in another way. Let me know how you\\'d like to proceed!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(\"get me ZF-3005\", context=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6ccb8-4c94-4ee3-8db9-fb5aa54bfd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085421d-7e23-4f04-bb2e-743917070c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
