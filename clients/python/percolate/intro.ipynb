{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92539e55-6700-4adc-86f9-dad08a531481",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "- This introduction is the easiest way for Python folks to play with Percolate\n",
    "- We provider the Postgres client using the Docker compose connection parameteres as defaults\n",
    "- We can learn how to register entities after which everyone else becomes possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493aa704-958c-41a6-b73f-9ed4408bb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import percolate\n",
    "from percolate.services import PostgresService\n",
    "pg = PostgresService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b8127-f33b-41a4-a499-9844d124978b",
   "metadata": {},
   "source": [
    "## Registering entities which are Agents is the key way to use Percolate\n",
    "- entity models describe agents completely\n",
    "- Percolate assumes agents are serializable in the \"Agent\" model which has structured response, sytem prompt and external function refs\n",
    "- We register Entities as tables that can store data, as Agents that can allow interaction with data\n",
    "- Agents are added as structured tables but other indexes are added too; embeddings on fields that need them and graph node registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7403bc-2b7c-429d-8a8f-fae30124234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.models.p8 import Project, Agent, ModelField, LanguageModelApi, Function\n",
    "\n",
    "#we register the core models - these are added by scripts in install anyway but it illustrates for 'bring your own'\n",
    "for model in [Project, Agent, ModelField, LanguageModelApi, Function]:\n",
    "    repo = pg.repository(model)\n",
    "    repo.register(register_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe693a-110a-4801-b999-813f416beabe",
   "metadata": {},
   "source": [
    "## Percolate configures Langauge models and assumes we can load tokens from the env\n",
    "- While not recommended in production, for simplicity you might add tokens locally in your database\n",
    "- The example below registers unique model names - the name is sometimes of the from provider-model if you want to select an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37c76e-2b3d-4fbd-9eb7-a6194fd65948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.utils import make_uuid\n",
    "import os\n",
    "\n",
    "models = [\n",
    "    LanguageModelApi(id = make_uuid('gpt-4o-2024-08-06'), name = 'gpt-4o-2024-08-06', scheme='openai', completions_uri='https://api.openai.com/v1/chat/completions', token_env_key='OPENAI_API_KEY', token=os.environ['OPENAI_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('gpt-4o-mini'), name = 'gpt-4o-mini', scheme='openai', completions_uri='https://api.openai.com/v1/chat/completions', token_env_key='OPENAI_API_KEY', token=os.environ['OPENAI_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('cerebras-llama3.1-8b'), name = 'cerebras-llama3.1-8b', model='llama3.1-8b', scheme='openai', completions_uri='https://api.cerebras.ai/v1/chat/completions', token_env_key='CEREBRAS_API_KEY', token=os.environ['CEREBRAS_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('groq-llama-3.3-70b-versatile'), name = 'groq-llama-3.3-70b-versatile', model='llama-3.3-70b-versatile', scheme='openai', completions_uri='https://api.groq.com/openai/v1/chat/completions', token_env_key='GROQ_API_KEY', token=os.environ['GROQ_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('claude-3-5-sonnet-20241022'), name = 'claude-3-5-sonnet-20241022', scheme='anthropic', completions_uri='https://api.anthropic.com/v1/messages', token_env_key='ANTHROPIC_API_KEY',token=os.environ['ANTHROPIC_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('gemini-1.5-flash'), name = 'gemini-1.5-flash', scheme='google', completions_uri='https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent', token_env_key='GEMINI_API_KEY', token=os.environ['GEMINI_API_KEY']),\n",
    "    LanguageModelApi(id = make_uuid('deepseek-chat'), name = 'deepseek-chat', scheme='openai', completions_uri='https://api.deepseek.com/chat/completions', token_env_key='DEEPSEEK_API_KEY', token=os.environ['DEEPSEEK_API_KEY']),\n",
    "]\n",
    "\n",
    "fetched=pg.repository(LanguageModelApi).update_records(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fde5e-8099-4959-bd4c-28f1375474a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
