{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50635797",
   "metadata": {},
   "source": [
    "# Working with Message Stack payloads \n",
    "- there are currently three support schemes; openai, google, anthropic\n",
    "- these have slightyl different payload structure for tool calls and responses in particular\n",
    "- generally, we want to ACK a tool call with an id and follow it with a response in the message stack\n",
    "- anthropic has a tool block and google has a functionResponse while open AI is easier with just the typically message with role and content\n",
    "- we can test read message stacks as instructions from the database in different contexts\n",
    "    - for a user question; trivial \n",
    "    - for a tool request with tool stack\n",
    "    - for agents that provider system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffeeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import percolate as p8\n",
    "from percolate.models.p8 import AIResponse\n",
    "from percolate.services import PostgresService\n",
    "from percolate.services.llm.LanguageModel import request_anthropic,request_google,request_openai\n",
    "from pydantic import BaseModel, model_validator, Field\n",
    "import typing\n",
    "import uuid\n",
    "\n",
    "pg = PostgresService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3cf688",
   "metadata": {},
   "source": [
    "### illustrate that in each scheme we read messages that are ready for that scheme and functions too\n",
    "- there is a corresponding database request_x that reads data in the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873008f0",
   "metadata": {},
   "source": [
    "## The first test should take a singel turn example id\n",
    "- at this point you have created a request with any scheme using e.g. percolate_with_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8486e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session_id = '8c51c161-7ac8-db55-68ec-7255ea4983e0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a609ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "goo_mm =  [d for d in pg.execute(f\"\"\" select * from p8.get_google_messages('{test_session_id}') \"\"\")[0]['messages']]  \n",
    "fns =  [d for d in pg.execute(f\"\"\" select * from p8.get_tools_by_name(ARRAY['get_pet_findByStatus'],'google') \"\"\")[0]['get_tools_by_name']]  \n",
    "request_google(goo_mm,fns).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1171d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_mm = [d for d in pg.execute(f\"\"\" select * from p8.get_anthropic_messages('{test_session_id}') \"\"\")[0]['messages']]\n",
    "fns =  [d for d in pg.execute(f\"\"\" select * from p8.get_tools_by_name(ARRAY['get_pet_findByStatus'],'anthropic') \"\"\")[0]['get_tools_by_name']]  \n",
    "request_anthropic(ant_mm,fns).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5b3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = [d for d in pg.execute(f\"\"\" select * from p8.get_canonical_messages('{test_session_id}') \"\"\")[0]['messages']]\n",
    "fns =  [d for d in pg.execute(f\"\"\" select * from p8.get_tools_by_name(ARRAY['get_pet_findByStatus']) \"\"\")[0]['get_tools_by_name']]  \n",
    "request_openai(mm,fns).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e596c",
   "metadata": {},
   "source": [
    "## Longer turn tests\n",
    "- make sure function calls and responses are paired properly \n",
    "- test injecting in new quuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d97d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
