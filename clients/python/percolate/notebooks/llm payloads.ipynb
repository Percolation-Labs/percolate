{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6766c4e",
   "metadata": {},
   "source": [
    "# Working with Message Stack payloads \n",
    "- there are currently three support schemes; openai, google, anthropic\n",
    "- these have slightyl different payload structure for tool calls and responses in particular\n",
    "- generally, we want to ACK a tool call with an id and follow it with a response in the message stack\n",
    "- anthropic has a tool block and google has a functionResponse while open AI is easier with just the typically message with role and content\n",
    "- we can test read message stacks as instructions from the database in different contexts\n",
    "    - for a user question; trivial \n",
    "    - for a tool request with tool stack\n",
    "    - for agents that provider system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open ai example\n",
    "{\n",
    "  \"model\": \"gpt-4-turbo\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Give me election voting info and check the latest news on AI.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": null,\n",
    "      \"tool_calls\": [\n",
    "        {\n",
    "          \"id\": \"tool_1\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": {\n",
    "            \"name\": \"get_policy\",\n",
    "            \"arguments\": {\n",
    "              \"category\": \"election_voting\"\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"tool_2\",\n",
    "          \"type\": \"function\",\n",
    "          \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"arguments\": {\n",
    "              \"query\": \"latest news on AI\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_use_id\": \"tool_1\",\n",
    "      \"name\": \"get_policy\",\n",
    "      \"content\": \"Election voting information: [Details here...]\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"tool\",\n",
    "      \"tool_use_id\": \"tool_2\",\n",
    "      \"name\": \"search\",\n",
    "      \"content\": \"Latest AI news: [Top headlines here...]\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b4b132e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_stack(question:str, session_id: str=None, agent_or_system_prompt:str=None, scheme:str='openai' ):\n",
    "    \"\"\"\n",
    "    the stack is built with just the questions and prompt unless there are data in the session\n",
    "    the canonical form has roles; user, tool, assistant\n",
    "    for google the role maps not user to model\n",
    "    for anthropic the role maps tool to user\n",
    "    \n",
    "    for google the parts are mapped\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5d7dbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import percolate as p8\n",
    "from percolate.models.p8 import AIResponse\n",
    "fns =[{\n",
    "  \"name\": \"get_weather\",\n",
    "  \"description\": \"Get the weather forecast for a specific city and date\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"city\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The city for which to get the weather forecast\"\n",
    "      },\n",
    "      \"date\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The date for the weather forecast (YYYY-MM-DD)\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"city\", \"date\"]\n",
    "  }\n",
    "}]\n",
    "#p8.repository(AIResponse).register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b69e6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from percolate.services import PostgresService\n",
    "import uuid\n",
    "uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e03f6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, model_validator, Field\n",
    "import typing\n",
    "\n",
    "class OpenAIMessage(BaseModel):\n",
    "    role: str\n",
    "    content: typing.Optional[str] = Field('', desscription='text content')\n",
    "    tool_calls: typing.Optional[typing.List[dict]|dict]\n",
    "    tool_call_id: typing.Optional[str] = None\n",
    "    @model_validator(mode='before')\n",
    "    @classmethod\n",
    "    def _val(cls,values):\n",
    "        if tool_calls:= values.get('tool_calls'):\n",
    "            if isinstance(tool_calls,dict):\n",
    "                values['tool_calls'] = [tool_calls]\n",
    "        return values\n",
    "\n",
    "pg = PostgresService()\n",
    "\n",
    "\n",
    "sid='d0d4a69c-dd9d-11ef-b115-7606330c2360'\n",
    "q = AIResponse( id=str(uuid.uuid1()), session_id=sid, role='user', content=\"What's the weather in Paris tomorrow?\", tokens_in=0, tokens_out=0, status='QUESTION', model_name='gpt-4o-mini')\n",
    "r = AIResponse.from_open_ai_response({'id': 'chatcmpl-AugmVtbKSogrlrGVbaENikjA5JCvl',\n",
    " 'object': 'chat.completion',\n",
    " 'created': 1738074183,\n",
    " 'model': 'gpt-4o-mini-2024-07-18',\n",
    " 'choices': [{'index': 0,\n",
    "   'message': {'role': 'assistant',\n",
    "    'content': None,\n",
    "    'tool_calls': [{'id': 'call_YCzly4yPh2l1QDP0WYZVi1K8',\n",
    "      'type': 'function',\n",
    "      'function': {'name': 'get_weather',\n",
    "       'arguments': '{\"city\":\"Paris\",\"date\":\"2023-10-05\"}'}}],\n",
    "    'refusal': None},\n",
    "   'logprobs': None,\n",
    "   'finish_reason': 'tool_calls'}],\n",
    " 'usage': {'prompt_tokens': 81,\n",
    "  'completion_tokens': 24,\n",
    "  'total_tokens': 105,\n",
    "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
    "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
    "   'audio_tokens': 0,\n",
    "   'accepted_prediction_tokens': 0,\n",
    "   'rejected_prediction_tokens': 0}},\n",
    " 'service_tier': 'default',\n",
    " 'system_fingerprint': 'fp_72ed7ab54c'},sid=sid)\n",
    "\n",
    "a = AIResponse( id=str(uuid.uuid1()), session_id=sid, role='tool', content=\"Its pretty nice\", tool_eval_data={'id': 'call_YCzly4yPh2l1QDP0WYZVi1K8','content':\"Its pretty nice\", 'name': 'get_weather'}, tokens_in=0, tokens_out=0, status='TOOL_RESPONSE', model_name='gpt-4o-mini')\n",
    "pg.update_records([r,a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d11f0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from percolate.models.p8.types import _OpenAIMessage\n",
    "\n",
    "mm = [d for d in pg.execute(f\"\"\"  select * from p8.get_anthropic_messages('what is the waether in paris on 2023-10-05', 'd0d4a69c-dd9d-11ef-b115-7606330c2360', 'use the functions to answer the users question') \"\"\")[0]['messages']]\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5eac2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = [d for d in pg.execute(f\"\"\" select * from p8.get_canonical_messages('b5c70717-a5a1-390e-bceb-1c5b064016a9') \"\"\")[0]['messages']]\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "23f9ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "aa451df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = request_openai(mm)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "527d7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_system_text(data):\n",
    "    system_text = '\\n'.join(\n",
    "        item['content'][0]['text'] for item in data if item['role'] == 'system'\n",
    "    )\n",
    "    return system_text\n",
    "combine_system_text(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4f55df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open AI Scheme\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "def request_openai(messages,functions=fns):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    #mm = [_OpenAIMessage.from_message(d) for d in pg.execute(f\"\"\"  select * from p8.get_canonical_messages(NULL, '2bc7f694-dd85-11ef-9aff-7606330c2360') \"\"\")[0]['messages']]\n",
    "    #request_openai(mm)\n",
    "    \n",
    "    \"\"\"place all system prompts at the start\"\"\"\n",
    "    \n",
    "    messages = [m if isinstance(m,dict) else m.model_dump() for m in messages]\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.environ.get('OPENAI_API_KEY')}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": messages,\n",
    "        \"tools\":  [{'type': 'function', 'function': f} for f in fns or []]\n",
    "    }\n",
    "    \n",
    "    return requests.post(url, headers=headers, data=json.dumps(data))\n",
    " \n",
    "\n",
    "def request_google(messages, functinos=fns):\n",
    "    \"\"\"\n",
    "    https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling\n",
    "    \n",
    "    expected tool call parts [{'functionCall': {'name': 'get_weather', 'args': {'date': '2024-07-27', 'city': 'Paris'}}}]\n",
    "    \"\"\"\n",
    "    def last_message_not_function_response(items):\n",
    "        if not items:\n",
    "            return True\n",
    "        msg = items[-1]\n",
    "        print(msg)\n",
    "        if 'functionResponse' in msg['parts'][0].keys():\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "        \n",
    "    system_prompt = [m for m in messages if m['role']=='system']\n",
    "\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={os.environ.get('GEMINI_API_KEY')}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    \"\"\"important not to include system prompt - you can get some cryptic messages\"\"\"\n",
    "    data = {\n",
    "        \"contents\": [m for m in messages if m['role'] !='system']\n",
    "    }\n",
    "     \n",
    "    if system_prompt:\n",
    "        data['system_instruction'] = '\\n'.join( item['content'][0]['text'] for item in system_prompts )\n",
    "    \n",
    "    \"\"\"i have seen gemini call the tool even when it was the data if this mode is set\"\"\"\n",
    "    if fns and last_message_not_function_response(messages):\n",
    "        data.update(\n",
    "           { \"tool_config\": {\n",
    "              \"function_calling_config\": {\"mode\": \"ANY\"}\n",
    "            },\n",
    "            \"tools\": [{'function_declarations': fns}]}\n",
    "        )\n",
    "        \n",
    "    return requests.post(url, headers=headers, data=json.dumps(data))\n",
    " \n",
    "\n",
    "def request_anthropic(messages, functinos=fns):\n",
    "    url = \"https://api.anthropic.com/v1/messages\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"x-api-key\":  os.environ.get('ANTHROPIC_API_KEY'),\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def _adapt_tools_for_anthropic( functions: typing.List[dict]):\n",
    "            \"\"\"slightly different dialect of function wrapper - rename parameters to input_schema\"\"\"\n",
    "            def _rewrite(d):\n",
    "                return {\n",
    "                    'name' : d['name'],\n",
    "                    'input_schema': d['parameters'],\n",
    "                    'description': d['description']\n",
    "                } \n",
    "            return [_rewrite(f) for f in functions]\n",
    "\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"claude-3-5-sonnet-20241022\",\n",
    "        \"max_tokens\": 1024,\n",
    "        \"messages\": [m for m in messages if m['role'] !='system'],\n",
    "        \"tools\": _adapt_tools_for_anthropic(fns) if fns else None\n",
    "    }\n",
    "    \n",
    "    system_prompt = [m for m in messages if m['role']=='system']\n",
    "   \n",
    "    if system_prompt:\n",
    "        data['system'] = '\\n'.join( item['content'][0]['text'] for item in system_prompt )\n",
    "    \n",
    "    return requests.post(url, headers=headers, data=json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f72b8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://api.anthropic.com/v1/messages\"\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#     \"x-api-key\":  os.environ.get('ANTHROPIC_API_KEY'),\n",
    "#     \"anthropic-version\": \"2023-06-01\",\n",
    "# }\n",
    "\n",
    "# data = {\n",
    "#     \"model\": \"claude-3-5-sonnet-20241022\",\n",
    "#     \"max_tokens\": 1024,\n",
    "#     \"messages\": [\n",
    "#         {\"role\": \"user\", \"content\": \"What's the weather in Paris tomorrow?\"}\n",
    "#     ],\n",
    "#     \"tools\":_adapt_tools_for_anthropic(fns) if fns else None\n",
    "# }\n",
    "# data = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# data.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a3aba8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_anthropic(mm).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79f548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
